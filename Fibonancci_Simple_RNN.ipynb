{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fibonancci-Simple-RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxYha/rMtBdjRMD7uqoO/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kzis/DL/blob/master/Fibonancci_Simple_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wKc6VGWdM6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHXoYV-8dPVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH6NDeV0dSOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "from tensorflow.random import set_seed\n",
        "seed(112)\n",
        "set_seed(112)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oie06J2dgI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "2a2b09d7-7c5f-4624-d54c-34c4c890a26b"
      },
      "source": [
        "fib_data = pd.read_csv('fib87.csv', nrows=37)\n",
        "print(fib_data.shape)\n",
        "fib_data['num'] = fib_data['num'].astype(np.uint64)\n",
        "fib_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num\n",
              "0    0\n",
              "1    1\n",
              "2    1\n",
              "3    2\n",
              "4    3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mUEVLu4j54s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f32c91c8-ed74-420c-a6d5-901240fdcd9f"
      },
      "source": [
        "fib_list = fib_data.values.tolist()\n",
        "print(fib_list)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0], [1], [1], [2], [3], [5], [8], [13], [21], [34], [55], [89], [144], [233], [377], [610], [987], [1597], [2584], [4181], [6765], [10946], [17711], [28657], [46368], [75025], [121393], [196418], [317811], [514229], [832040], [1346269], [2178309], [3524578], [5702887], [9227465], [14930352]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3m1cWDvkRRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "17d577ab-14cb-4346-a273-50f764a5da70"
      },
      "source": [
        "def flatten_list(l):\n",
        "  flat_list = []\n",
        "  for sublist in l:\n",
        "      for item in sublist:\n",
        "          flat_list.append(item)\n",
        "  return flat_list\n",
        "\n",
        "fib_list_flatten = flatten_list(fib_list)\n",
        "print(fib_list_flatten)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5702887, 9227465, 14930352]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UK4fbN-inzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_put = []\n",
        "def create_fib_dataset(fib_list_flatten,input_n,output_n):\n",
        "  for idx, val in enumerate(fib_list_flatten):\n",
        "    if(idx == len(fib_list_flatten)-input_n-output_n) : \n",
        "      print(idx)\n",
        "      print(len(fib_list_flatten)-input_n-output_n)\n",
        "      print(idx,idx+input_n)\n",
        "      print(idx+input_n,idx+input_n+output_n)\n",
        "      break\n",
        "    temp = []\n",
        "    x = fib_list_flatten[idx:idx+input_n] \n",
        "    y = fib_list_flatten[idx+input_n:idx+input_n+output_n]\n",
        "    temp.append(idx)\n",
        "    temp.append(x)\n",
        "    temp.append(y)\n",
        "    out_put.append(temp)\n",
        "  return out_put"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJXnsAMeinJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "cdab8545-4966-48a0-bb26-cf32721875bb"
      },
      "source": [
        "input_n = 7\n",
        "output_n = 5\n",
        "data_list = create_fib_dataset(fib_list_flatten,input_n,output_n)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n",
            "25\n",
            "25 32\n",
            "32 37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B5svpojiaJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "bd8a0af4-665d-4f2e-8f98-42d5132f1696"
      },
      "source": [
        "col_name = [\"#\", \"X\", \"Y\"]\n",
        "df = pd.DataFrame(data_list, columns=col_name)\n",
        "df.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[0, 1, 1, 2, 3, 5, 8]</td>\n",
              "      <td>[13, 21, 34, 55, 89]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 2, 3, 5, 8, 13]</td>\n",
              "      <td>[21, 34, 55, 89, 144]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[1, 2, 3, 5, 8, 13, 21]</td>\n",
              "      <td>[34, 55, 89, 144, 233]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[2, 3, 5, 8, 13, 21, 34]</td>\n",
              "      <td>[55, 89, 144, 233, 377]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[3, 5, 8, 13, 21, 34, 55]</td>\n",
              "      <td>[89, 144, 233, 377, 610]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   #                          X                         Y\n",
              "0  0      [0, 1, 1, 2, 3, 5, 8]      [13, 21, 34, 55, 89]\n",
              "1  1     [1, 1, 2, 3, 5, 8, 13]     [21, 34, 55, 89, 144]\n",
              "2  2    [1, 2, 3, 5, 8, 13, 21]    [34, 55, 89, 144, 233]\n",
              "3  3   [2, 3, 5, 8, 13, 21, 34]   [55, 89, 144, 233, 377]\n",
              "4  4  [3, 5, 8, 13, 21, 34, 55]  [89, 144, 233, 377, 610]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTkJl_2Y1HIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c4433afd-2efa-4a84-967c-068e8376fe99"
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>[89, 144, 233, 377, 610, 987, 1597]</td>\n",
              "      <td>[2584, 4181, 6765, 10946, 17711]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17</td>\n",
              "      <td>[1597, 2584, 4181, 6765, 10946, 17711, 28657]</td>\n",
              "      <td>[46368, 75025, 121393, 196418, 317811]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>[8, 13, 21, 34, 55, 89, 144]</td>\n",
              "      <td>[233, 377, 610, 987, 1597]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>[233, 377, 610, 987, 1597, 2584, 4181]</td>\n",
              "      <td>[6765, 10946, 17711, 28657, 46368]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>[610, 987, 1597, 2584, 4181, 6765, 10946]</td>\n",
              "      <td>[17711, 28657, 46368, 75025, 121393]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    #  ...                                       Y\n",
              "0  11  ...        [2584, 4181, 6765, 10946, 17711]\n",
              "1  17  ...  [46368, 75025, 121393, 196418, 317811]\n",
              "2   6  ...              [233, 377, 610, 987, 1597]\n",
              "3  13  ...      [6765, 10946, 17711, 28657, 46368]\n",
              "4  15  ...    [17711, 28657, 46368, 75025, 121393]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeHASGanqBWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "f33b17e1-593b-47f9-873d-8bac7e912c4f"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "\n",
        "my_rnn = Sequential()\n",
        "\n",
        "# batch_size=None, time_steps=None, input_dim=1\n",
        "# Output from this layer is (batch_size,units)=(batch_size,10)\n",
        "my_rnn.add( SimpleRNN( units=20, input_shape=(None,1) ) )\n",
        "\n",
        "# Use the default 'linear activation'\n",
        "my_rnn.add( Dense(5) )\n",
        "\n",
        "my_rnn.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 20)                440       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 105       \n",
            "=================================================================\n",
            "Total params: 545\n",
            "Trainable params: 545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND7mCDK1qsju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import mean_squared_error\n",
        "\n",
        "adam = Adam(lr=0.01)\n",
        "my_rnn.compile( loss=\"mse\", optimizer=adam, metrics=[mean_squared_error] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXB3WBFCq1Fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bdfe5215-50a9-4aa0-b273-7888b042edbc"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Min-max scaling to normalize the data to the range [0, 1]\n",
        "# .fit_transform expects 2D input\n",
        "x_train = df.iloc[0:10]['X'].to_list()\n",
        "x_test = df.iloc[10:15]['X'].to_list()\n",
        "x_val = df.iloc[15:24]['X'].to_list()\n",
        "y_train= df.iloc[0:10]['Y'].to_list()\n",
        "y_test= df.iloc[10:15]['Y'].to_list()\n",
        "y_val= df.iloc[15:24]['Y'].to_list()\n",
        "\n",
        "x_minmax_norm = MinMaxScaler().fit(x_train)\n",
        "print( \"x min-max:\" , x_minmax_norm.data_min_ , x_minmax_norm.data_max_ )\n",
        "\n",
        "y_minmax_norm = MinMaxScaler().fit( y_train )\n",
        "print( \"y min-max:\" , y_minmax_norm.data_min_ , y_minmax_norm.data_max_ ) \n",
        "\n",
        "# Apply the normalizer to validation and test sets as well\n",
        "x_train = x_minmax_norm.transform( x_train )\n",
        "x_test = x_minmax_norm.transform( x_test )\n",
        "x_val = x_minmax_norm.transform( x_val )\n",
        "y_train = y_minmax_norm.transform( y_train )\n",
        "y_test = y_minmax_norm.transform( y_test )\n",
        "y_val = y_minmax_norm.transform( y_val )\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x min-max: [0. 1. 1. 2. 3. 5. 8.] [ 28657.  46368.  75025. 121393. 196418. 317811. 514229.]\n",
            "y min-max: [13. 21. 34. 55. 89.] [ 832040. 1346269. 2178309. 3524578. 5702887.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8LvKfXvuwnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "2636f0cf-f7ce-494c-f0fd-6f33de98e9f1"
      },
      "source": [
        "print(\"Dimension of x before changed:\")\n",
        "print( \"x_train:\" , x_train.shape )\n",
        "print( \"x_test:\" , x_test.shape )\n",
        "print( \"x_val:\" , x_val.shape )\n",
        "\n",
        "x_train = x_train[ ..., np.newaxis ]\n",
        "x_test = x_test[ ..., np.newaxis ]\n",
        "x_val = x_val[ ..., np.newaxis ]\n",
        "\n",
        "print(\"\\nDimension of x after changed:\")\n",
        "print( \"x_train:\" , x_train.shape )\n",
        "print( \"x_test:\" , x_test.shape )\n",
        "print( \"x_val:\" , x_val.shape )\n",
        "\n",
        "# Convert everything to the default of float32\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_test = x_test.astype(np.float32)\n",
        "x_val = x_val.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "y_val = y_val.astype(np.float32)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension of x before changed:\n",
            "x_train: (10, 7)\n",
            "x_test: (5, 7)\n",
            "x_val: (9, 7)\n",
            "\n",
            "Dimension of x after changed:\n",
            "x_train: (10, 7, 1)\n",
            "x_test: (5, 7, 1)\n",
            "x_val: (9, 7, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQtGkxdlvZ2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#checkpoint = ModelCheckpoint('ex10_04_RNN_best_{epoch:04d}.hdf5', save_best_only=True, monitor=\"val_loss\", mode='min')  \n",
        "checkpoint = ModelCheckpoint('ex10_04_RNN_best.hdf5', save_best_only=True, monitor=\"val_loss\", mode='min', save_weights_only=False)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKZAHYtku3AV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed7810ca-d7cd-481f-b9d6-a12608c7e6d4"
      },
      "source": [
        "hist = my_rnn.fit ( x_train, y_train, validation_data=(x_val,y_val), batch_size=64, epochs=100, callbacks=[checkpoint] )"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.0037e-05 - mean_squared_error: 1.0037e-05 - val_loss: 9.2009e-06 - val_mean_squared_error: 9.2009e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.5860e-06 - mean_squared_error: 7.5860e-06 - val_loss: 6.9063e-06 - val_mean_squared_error: 6.9063e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4.6951e-06 - mean_squared_error: 4.6951e-06 - val_loss: 4.5869e-06 - val_mean_squared_error: 4.5869e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 1s 509ms/step - loss: 2.2265e-06 - mean_squared_error: 2.2265e-06 - val_loss: 3.0014e-06 - val_mean_squared_error: 3.0014e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.2945e-07 - mean_squared_error: 9.2945e-07 - val_loss: 2.9277e-06 - val_mean_squared_error: 2.9277e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.2606e-06 - mean_squared_error: 1.2606e-06 - val_loss: 4.1209e-06 - val_mean_squared_error: 4.1209e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3013e-06 - mean_squared_error: 2.3013e-06 - val_loss: 5.7827e-06 - val_mean_squared_error: 5.7827e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.2542e-06 - mean_squared_error: 3.2542e-06 - val_loss: 6.8730e-06 - val_mean_squared_error: 6.8730e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.8090e-06 - mean_squared_error: 3.8090e-06 - val_loss: 6.6674e-06 - val_mean_squared_error: 6.6674e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.6308e-06 - mean_squared_error: 3.6308e-06 - val_loss: 5.4868e-06 - val_mean_squared_error: 5.4868e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8907e-06 - mean_squared_error: 2.8907e-06 - val_loss: 4.2239e-06 - val_mean_squared_error: 4.2239e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.0216e-06 - mean_squared_error: 2.0216e-06 - val_loss: 3.5908e-06 - val_mean_squared_error: 3.5908e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.2791e-06 - mean_squared_error: 1.2791e-06 - val_loss: 3.6656e-06 - val_mean_squared_error: 3.6656e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 8.5199e-07 - mean_squared_error: 8.5199e-07 - val_loss: 4.0143e-06 - val_mean_squared_error: 4.0143e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 8.0770e-07 - mean_squared_error: 8.0770e-07 - val_loss: 4.3005e-06 - val_mean_squared_error: 4.3005e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.0496e-06 - mean_squared_error: 1.0496e-06 - val_loss: 4.4067e-06 - val_mean_squared_error: 4.4067e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3360e-06 - mean_squared_error: 1.3360e-06 - val_loss: 4.4169e-06 - val_mean_squared_error: 4.4169e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.4696e-06 - mean_squared_error: 1.4696e-06 - val_loss: 4.4500e-06 - val_mean_squared_error: 4.4500e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3955e-06 - mean_squared_error: 1.3955e-06 - val_loss: 4.3471e-06 - val_mean_squared_error: 4.3471e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.0869e-06 - mean_squared_error: 1.0869e-06 - val_loss: 4.0410e-06 - val_mean_squared_error: 4.0410e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.1094e-07 - mean_squared_error: 7.1094e-07 - val_loss: 3.7163e-06 - val_mean_squared_error: 3.7163e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.8652e-07 - mean_squared_error: 4.8652e-07 - val_loss: 3.5216e-06 - val_mean_squared_error: 3.5216e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.1640e-07 - mean_squared_error: 4.1640e-07 - val_loss: 3.6041e-06 - val_mean_squared_error: 3.6041e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.9766e-07 - mean_squared_error: 4.9766e-07 - val_loss: 3.9034e-06 - val_mean_squared_error: 3.9034e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.4383e-07 - mean_squared_error: 6.4383e-07 - val_loss: 4.1477e-06 - val_mean_squared_error: 4.1477e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.7171e-07 - mean_squared_error: 6.7171e-07 - val_loss: 4.2752e-06 - val_mean_squared_error: 4.2752e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.9571e-07 - mean_squared_error: 5.9571e-07 - val_loss: 4.3306e-06 - val_mean_squared_error: 4.3306e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.6352e-07 - mean_squared_error: 4.6352e-07 - val_loss: 4.3518e-06 - val_mean_squared_error: 4.3518e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0550e-07 - mean_squared_error: 3.0550e-07 - val_loss: 4.4199e-06 - val_mean_squared_error: 4.4199e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3296e-07 - mean_squared_error: 2.3296e-07 - val_loss: 4.5005e-06 - val_mean_squared_error: 4.5005e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3800e-07 - mean_squared_error: 2.3800e-07 - val_loss: 4.5671e-06 - val_mean_squared_error: 4.5671e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.6600e-07 - mean_squared_error: 2.6600e-07 - val_loss: 4.6575e-06 - val_mean_squared_error: 4.6575e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1060e-07 - mean_squared_error: 3.1060e-07 - val_loss: 4.7044e-06 - val_mean_squared_error: 4.7044e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1754e-07 - mean_squared_error: 3.1754e-07 - val_loss: 4.6360e-06 - val_mean_squared_error: 4.6360e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8025e-07 - mean_squared_error: 2.8025e-07 - val_loss: 4.4611e-06 - val_mean_squared_error: 4.4611e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.3160e-07 - mean_squared_error: 2.3160e-07 - val_loss: 4.2741e-06 - val_mean_squared_error: 4.2741e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.7336e-07 - mean_squared_error: 1.7336e-07 - val_loss: 4.2376e-06 - val_mean_squared_error: 4.2376e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3078e-07 - mean_squared_error: 1.3078e-07 - val_loss: 4.3853e-06 - val_mean_squared_error: 4.3853e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1815e-07 - mean_squared_error: 1.1815e-07 - val_loss: 4.5766e-06 - val_mean_squared_error: 4.5766e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.2464e-07 - mean_squared_error: 1.2464e-07 - val_loss: 4.6676e-06 - val_mean_squared_error: 4.6676e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.4362e-07 - mean_squared_error: 1.4362e-07 - val_loss: 4.6513e-06 - val_mean_squared_error: 4.6513e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5909e-07 - mean_squared_error: 1.5909e-07 - val_loss: 4.6587e-06 - val_mean_squared_error: 4.6587e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5711e-07 - mean_squared_error: 1.5711e-07 - val_loss: 4.7806e-06 - val_mean_squared_error: 4.7806e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3633e-07 - mean_squared_error: 1.3633e-07 - val_loss: 4.9392e-06 - val_mean_squared_error: 4.9392e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.0723e-07 - mean_squared_error: 1.0723e-07 - val_loss: 4.9869e-06 - val_mean_squared_error: 4.9869e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.1860e-08 - mean_squared_error: 8.1860e-08 - val_loss: 4.8936e-06 - val_mean_squared_error: 4.8936e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.8564e-08 - mean_squared_error: 6.8564e-08 - val_loss: 4.7960e-06 - val_mean_squared_error: 4.7960e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.2023e-08 - mean_squared_error: 7.2023e-08 - val_loss: 4.8316e-06 - val_mean_squared_error: 4.8316e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 8.1238e-08 - mean_squared_error: 8.1238e-08 - val_loss: 4.9718e-06 - val_mean_squared_error: 4.9718e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.7617e-08 - mean_squared_error: 8.7617e-08 - val_loss: 5.0579e-06 - val_mean_squared_error: 5.0579e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.8075e-08 - mean_squared_error: 8.8075e-08 - val_loss: 4.9886e-06 - val_mean_squared_error: 4.9886e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.8100e-08 - mean_squared_error: 7.8100e-08 - val_loss: 4.8453e-06 - val_mean_squared_error: 4.8453e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.6356e-08 - mean_squared_error: 6.6356e-08 - val_loss: 4.7824e-06 - val_mean_squared_error: 4.7824e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.7638e-08 - mean_squared_error: 5.7638e-08 - val_loss: 4.8434e-06 - val_mean_squared_error: 4.8434e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.1875e-08 - mean_squared_error: 5.1875e-08 - val_loss: 4.9267e-06 - val_mean_squared_error: 4.9267e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.2285e-08 - mean_squared_error: 5.2285e-08 - val_loss: 4.9202e-06 - val_mean_squared_error: 4.9202e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.3191e-08 - mean_squared_error: 5.3191e-08 - val_loss: 4.8443e-06 - val_mean_squared_error: 4.8443e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.2770e-08 - mean_squared_error: 5.2770e-08 - val_loss: 4.8148e-06 - val_mean_squared_error: 4.8148e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.1841e-08 - mean_squared_error: 5.1841e-08 - val_loss: 4.8896e-06 - val_mean_squared_error: 4.8896e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.8266e-08 - mean_squared_error: 4.8266e-08 - val_loss: 5.0039e-06 - val_mean_squared_error: 5.0039e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.4915e-08 - mean_squared_error: 4.4915e-08 - val_loss: 5.0541e-06 - val_mean_squared_error: 5.0541e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.2055e-08 - mean_squared_error: 4.2055e-08 - val_loss: 5.0235e-06 - val_mean_squared_error: 5.0235e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.9338e-08 - mean_squared_error: 3.9338e-08 - val_loss: 4.9857e-06 - val_mean_squared_error: 4.9857e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.8113e-08 - mean_squared_error: 3.8113e-08 - val_loss: 4.9988e-06 - val_mean_squared_error: 4.9988e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.7263e-08 - mean_squared_error: 3.7263e-08 - val_loss: 5.0371e-06 - val_mean_squared_error: 5.0371e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.6624e-08 - mean_squared_error: 3.6624e-08 - val_loss: 5.0353e-06 - val_mean_squared_error: 5.0353e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.5824e-08 - mean_squared_error: 3.5824e-08 - val_loss: 4.9787e-06 - val_mean_squared_error: 4.9787e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.4211e-08 - mean_squared_error: 3.4211e-08 - val_loss: 4.9168e-06 - val_mean_squared_error: 4.9168e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2188e-08 - mean_squared_error: 3.2188e-08 - val_loss: 4.8987e-06 - val_mean_squared_error: 4.8987e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.0400e-08 - mean_squared_error: 3.0400e-08 - val_loss: 4.9182e-06 - val_mean_squared_error: 4.9182e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9269e-08 - mean_squared_error: 2.9269e-08 - val_loss: 4.9342e-06 - val_mean_squared_error: 4.9342e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8774e-08 - mean_squared_error: 2.8774e-08 - val_loss: 4.9275e-06 - val_mean_squared_error: 4.9275e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8629e-08 - mean_squared_error: 2.8629e-08 - val_loss: 4.9158e-06 - val_mean_squared_error: 4.9158e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8015e-08 - mean_squared_error: 2.8015e-08 - val_loss: 4.9214e-06 - val_mean_squared_error: 4.9214e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.6968e-08 - mean_squared_error: 2.6968e-08 - val_loss: 4.9411e-06 - val_mean_squared_error: 4.9411e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5764e-08 - mean_squared_error: 2.5764e-08 - val_loss: 4.9555e-06 - val_mean_squared_error: 4.9555e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.4541e-08 - mean_squared_error: 2.4541e-08 - val_loss: 4.9580e-06 - val_mean_squared_error: 4.9580e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.3864e-08 - mean_squared_error: 2.3864e-08 - val_loss: 4.9555e-06 - val_mean_squared_error: 4.9555e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.3339e-08 - mean_squared_error: 2.3339e-08 - val_loss: 4.9555e-06 - val_mean_squared_error: 4.9555e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.2910e-08 - mean_squared_error: 2.2910e-08 - val_loss: 4.9568e-06 - val_mean_squared_error: 4.9568e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.2559e-08 - mean_squared_error: 2.2559e-08 - val_loss: 4.9560e-06 - val_mean_squared_error: 4.9560e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2024e-08 - mean_squared_error: 2.2024e-08 - val_loss: 4.9542e-06 - val_mean_squared_error: 4.9542e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1578e-08 - mean_squared_error: 2.1578e-08 - val_loss: 4.9512e-06 - val_mean_squared_error: 4.9512e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1012e-08 - mean_squared_error: 2.1012e-08 - val_loss: 4.9431e-06 - val_mean_squared_error: 4.9431e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.0362e-08 - mean_squared_error: 2.0362e-08 - val_loss: 4.9293e-06 - val_mean_squared_error: 4.9293e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9771e-08 - mean_squared_error: 1.9771e-08 - val_loss: 4.9175e-06 - val_mean_squared_error: 4.9175e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9214e-08 - mean_squared_error: 1.9214e-08 - val_loss: 4.9169e-06 - val_mean_squared_error: 4.9169e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8891e-08 - mean_squared_error: 1.8891e-08 - val_loss: 4.9231e-06 - val_mean_squared_error: 4.9231e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.8679e-08 - mean_squared_error: 1.8679e-08 - val_loss: 4.9248e-06 - val_mean_squared_error: 4.9248e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.8467e-08 - mean_squared_error: 1.8467e-08 - val_loss: 4.9198e-06 - val_mean_squared_error: 4.9198e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.8178e-08 - mean_squared_error: 1.8178e-08 - val_loss: 4.9187e-06 - val_mean_squared_error: 4.9187e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.7763e-08 - mean_squared_error: 1.7763e-08 - val_loss: 4.9297e-06 - val_mean_squared_error: 4.9297e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.7321e-08 - mean_squared_error: 1.7321e-08 - val_loss: 4.9445e-06 - val_mean_squared_error: 4.9445e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6921e-08 - mean_squared_error: 1.6921e-08 - val_loss: 4.9477e-06 - val_mean_squared_error: 4.9477e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.6599e-08 - mean_squared_error: 1.6599e-08 - val_loss: 4.9384e-06 - val_mean_squared_error: 4.9384e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6348e-08 - mean_squared_error: 1.6348e-08 - val_loss: 4.9315e-06 - val_mean_squared_error: 4.9315e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6144e-08 - mean_squared_error: 1.6144e-08 - val_loss: 4.9365e-06 - val_mean_squared_error: 4.9365e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.5935e-08 - mean_squared_error: 1.5935e-08 - val_loss: 4.9451e-06 - val_mean_squared_error: 4.9451e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.5727e-08 - mean_squared_error: 1.5727e-08 - val_loss: 4.9436e-06 - val_mean_squared_error: 4.9436e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5482e-08 - mean_squared_error: 1.5482e-08 - val_loss: 4.9342e-06 - val_mean_squared_error: 4.9342e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFb83Rx0vMlA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f386fd67-3de0-4347-e915-4dcfc053b5e9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline                \n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss: mean squared error')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validate'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNBAopVSS00CglFJJTgOBUkoluf8PZtZ4HBmkmakAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCChGEcQwOvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7f614a26-2cf4-4ae5-f327-ff19482102ef"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Evaluate the model from the last epoch\n",
        "score = my_rnn.evaluate( x_test, y_test, verbose=0 )\n",
        "print( \"Test results (model from the last epoch):\", [ (my_rnn.metrics_names[i], score[i]) for i in range(len(score)) ] )\n",
        "\n",
        "# Load and evaluate the model from the best epoch\n",
        "my_rnn_best = load_model('ex10_04_RNN_best.hdf5', compile=True )\n",
        "score = my_rnn_best.evaluate( x_test, y_test, verbose=0 )\n",
        "print( \"Test results (model from the best epoch):\", [ (my_rnn_best.metrics_names[i], score[i]) for i in range(len(score)) ] )"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test results (model from the last epoch): [('loss', 0.0030376676004379988), ('mean_squared_error', 0.0030376676004379988)]\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Test results (model from the best epoch): [('loss', 0.002820130903273821), ('mean_squared_error', 0.002820130903273821)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBjr4wOSwaD5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "a031a8cd-65d4-4b3f-9b92-7c8ab48eccf1"
      },
      "source": [
        "y_test_predict = my_rnn.predict( x_test )            # last epoch\n",
        "y2_test_predict = my_rnn_best.predict( x_test )  # best epoch\n",
        "\n",
        "# Denormalize the value\n",
        "x_inv = x_minmax_norm.inverse_transform( x_test.reshape( (x_test.shape[0], x_test.shape[1]) )  )\n",
        "y_inv = y_minmax_norm.inverse_transform( y_test_predict )\n",
        "y2_inv = y_minmax_norm.inverse_transform( y2_test_predict )\n",
        "\n",
        "# Round all float values to their closest integers\n",
        "x_inv = np.around( x_inv )\n",
        "y_inv = np.around( y_inv )\n",
        "y2_inv = np.around( y2_inv )\n",
        "\n",
        "for i in range( x_inv.shape[0] ):\n",
        "    print( \"x_test[{}] = {}\".format( i, x_inv[i].reshape(1,x_inv[i].shape[0]) ) )\n",
        "    print( \"y_test_last_epoch[{}] = {}\".format( i, y_inv[i] ) )\n",
        "    print( \"y_test_best_epoch[{}] = {}\\n\".format( i, y2_inv[i] ) )"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test[0] = [[ 2.  3.  5.  8. 13. 21. 34.]]\n",
            "y_test_last_epoch[0] = [  82.  234.  365.  239. 1007.]\n",
            "y_test_best_epoch[0] = [ -562.   418.  2079.  1511. 10940.]\n",
            "\n",
            "x_test[1] = [[ 46368.  75025. 121393. 196418. 317811. 514229. 832040.]]\n",
            "y_test_last_epoch[1] = [1277977. 2007158. 3213012. 5188518. 8621649.]\n",
            "y_test_best_epoch[1] = [1281320. 2015993. 3227175. 5183076. 8672776.]\n",
            "\n",
            "x_test[2] = [[ 5.  8. 13. 21. 34. 55. 89.]]\n",
            "y_test_last_epoch[2] = [ 171.  377.  597.  614. 1606.]\n",
            "y_test_best_epoch[2] = [ -474.   560.  2309.  1884. 11534.]\n",
            "\n",
            "x_test[3] = [[ 55.  89. 144. 233. 377. 610. 987.]]\n",
            "y_test_last_epoch[3] = [ 1616.  2704.  4370.  6752. 11513.]\n",
            "y_test_best_epoch[3] = [  956.  2863.  6032.  8007. 21336.]\n",
            "\n",
            "x_test[4] = [[ 1.  2.  3.  5.  8. 13. 21.]]\n",
            "y_test_last_epoch[4] = [ 62. 201. 315. 144. 833.]\n",
            "y_test_best_epoch[4] = [ -582.   386.  2031.  1417. 10769.]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}